{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_XJcxqx22uj"
   },
   "source": [
    "## Using Gradio to create a simple interface.\n",
    "\n",
    "Check out the library on [github](https://github.com/gradio-app/gradio-UI) and see the [getting started](https://gradio.app/getting_started.html) page for more demos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUHtJ20jYqd9"
   },
   "source": [
    "We'll start with a basic function that greets an input name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "qtlFLbke2Sob",
    "outputId": "dce41c53-08d5-434e-9812-02207050bca7"
   },
   "outputs": [],
   "source": [
    "def draw(inp):\n",
    "    drawing = inp\n",
    "    drawing_filename = 'images/' + drawing.replace(' ', '_') + '.png'\n",
    "    if os.path.exists(drawing_filename):\n",
    "        print(\"found drawing \", drawing_filename)\n",
    "        return Image.open(drawing_filename) \n",
    "    print(\"generating drawing '\", drawing, \"'\", drawing_filename)\n",
    "    #pipe = StableDiffusionPipeline.from_pretrained(\"../stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"../stable-diffusion-2\", torch_dtype=torch.float16)\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "    image = pipe(drawing).images[0]  \n",
    "    image.seek(0)\n",
    "    image.save(drawing_filename)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R06dbZZaYJDq"
   },
   "source": [
    "Now we'll wrap this function with a Gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJUJLWQ92g6R",
    "outputId": "85f99754-24cf-4541-f836-13c7e8e97a02"
   },
   "outputs": [],
   "source": [
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "e200MmBU2aLT",
    "outputId": "a78fa20b-6e6a-4d49-ddec-3b7e7f88d55a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating drawing ' astronaut riding a horse in san francisco ' images/astronaut_riding_a_horse_in_san_francisco.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336cd8027f2b4d4797ca8e74b0e8ebcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/gradio/routes.py\", line 322, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 1015, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/gradio/blocks.py\", line 833, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/anyio/to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/tmp/ipykernel_648430/3170257752.py\", line 11, in draw\n",
      "    image = pipe(drawing).images[0]\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 529, in __call__\n",
      "    noise_pred = self.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/unet_2d_condition.py\", line 453, in forward\n",
      "    sample = upsample_block(\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/unet_2d_blocks.py\", line 1563, in forward\n",
      "    hidden_states = attn(hidden_states, encoder_hidden_states=encoder_hidden_states).sample\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/attention.py\", line 216, in forward\n",
      "    hidden_states = block(hidden_states, encoder_hidden_states=encoder_hidden_states, timestep=timestep)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/attention.py\", line 490, in forward\n",
      "    hidden_states = self.attn1(norm_hidden_states, attention_mask=attention_mask) + hidden_states\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/attention.py\", line 638, in forward\n",
      "    hidden_states = self._attention(query, key, value, attention_mask)\n",
      "  File \"/home/thoth/.local/lib/python3.10/site-packages/diffusers/models/attention.py\", line 654, in _attention\n",
      "    attention_scores = torch.baddbmm(\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.58 GiB (GPU 0; 7.79 GiB total capacity; 4.13 GiB already allocated; 833.19 MiB free; 5.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import binascii\n",
    "import glob\n",
    "import openai\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "demo = gr.Interface(fn=draw, inputs=\"text\", outputs=\"image\")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQheRaw5YVTL"
   },
   "source": [
    "That's all! Go ahead and open that share link in a new tab. Check out our [getting started](https://gradio.app/getting_started.html) page for more complicated demos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
